<!DOCTYPE html>
<html lang="zh-TW"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>A time-delay neural network architecture for isolated word recognition | ML Notes</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="A time-delay neural network architecture for isolated word recognition" />
<meta property="og:locale" content="zh_TW" />
<meta name="description" content="目標 提出 Time-delay Neural Network，在 IBM BDEV 語音辨識資料集上達到最好表現，並且不需要多餘的前處理 作者 Kevin J.Lang, Alex H.Waibel, Geoffrey E.Hinton 期刊/會議名稱 Neural Networks 發表時間 1990 論文連結 https://www.sciencedirect.com/science/article/pii/089360809090044L" />
<meta property="og:description" content="目標 提出 Time-delay Neural Network，在 IBM BDEV 語音辨識資料集上達到最好表現，並且不需要多餘的前處理 作者 Kevin J.Lang, Alex H.Waibel, Geoffrey E.Hinton 期刊/會議名稱 Neural Networks 發表時間 1990 論文連結 https://www.sciencedirect.com/science/article/pii/089360809090044L" />
<link rel="canonical" href="/acoustic%20modeling/2021/12/06/a-time-delay-neural-network-architecture-for-isolated-word-recognition.html" />
<meta property="og:url" content="/acoustic%20modeling/2021/12/06/a-time-delay-neural-network-architecture-for-isolated-word-recognition.html" />
<meta property="og:site_name" content="ML Notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-06T12:28:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="A time-delay neural network architecture for isolated word recognition" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-12-06T12:28:00+08:00","datePublished":"2021-12-06T12:28:00+08:00","description":"目標 提出 Time-delay Neural Network，在 IBM BDEV 語音辨識資料集上達到最好表現，並且不需要多餘的前處理 作者 Kevin J.Lang, Alex H.Waibel, Geoffrey E.Hinton 期刊/會議名稱 Neural Networks 發表時間 1990 論文連結 https://www.sciencedirect.com/science/article/pii/089360809090044L","headline":"A time-delay neural network architecture for isolated word recognition","mainEntityOfPage":{"@type":"WebPage","@id":"/acoustic%20modeling/2021/12/06/a-time-delay-neural-network-architecture-for-isolated-word-recognition.html"},"url":"/acoustic%20modeling/2021/12/06/a-time-delay-neural-network-architecture-for-isolated-word-recognition.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <script src="/assets/js/main.js"></script><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="ML Notes" /><link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8"
        src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js"></script>




  
      <!-- [function][get_value] true -->
  






  
      <!-- [function][get_value] #fff -->
  






  
      <!-- [function][get_value] #ff4e00 -->
  






  
      <!-- [function][get_value] uppercase -->
  

<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<!-- favicon. -->
<link rel='icon' type='image/png' sizes='16x16' href='/assets/images/favicon.png' />

<!-- Noto sans CJK source code: https://dotblogs.com.tw/shadow/2019/10/27/153832 -->
<style>
  @font-face {
    font-family: 'Noto Sans TC';
    font-style: normal;
    font-weight: 100;
    src: url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Thin.woff2) format('woff2'),
      url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Thin.woff) format('woff'),
      url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Thin.otf) format('opentype');
  }

  /*預設font-weight*/
  @font-face {
    font-family: 'Noto Sans TC';
    font-style: normal;
    font-weight: 400;
    src: url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Regular.woff2) format('woff2'),
      url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Regular.woff) format('woff'),
      url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Regular.otf) format('opentype');
  }

  @font-face {
    font-family: 'Noto Sans TC';
    font-style: normal;
    font-weight: 700;
    src: url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Bold.woff2) format('woff2'),
      url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Bold.woff) format('woff'),
      url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Bold.otf) format('opentype');
  }

  @font-face {
    font-family: 'Noto Sans TC';
    font-style: normal;
    font-weight: 900;
    src: url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Black.woff2) format('woff2'),
      url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Black.woff) format('woff'),
      url(//fonts.gstatic.com/ea/notosanstc/v1/NotoSansTC-Black.otf) format('opentype');
  }

  html,
  body {
    font-family: 'Noto Sans TC';
  }
</style></head>
<body>




  
      <!-- [function][get_value] uppercase -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value] true -->
  






  
      <!-- [function][get_value] true -->
  






  
      <!-- [function][get_value] 0 -->
  






  
      <!-- [function][get_value] 0 -->
  






  
      <!-- [function][get_value] 0 -->
  










  
      <!-- [function][get_value] 0 -->
  






  
      <!-- [function][get_value] true -->
  

<header class="site-header " role="banner">

  <div class="wrapper">
    <div class="site-header-inner"><span class="site-brand"><a class="site-brand-inner" rel="author" href="/">
  <img class="site-favicon" title="ML Notes" src="" onerror="this.style.display='none'">
  ML Notes
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>

          <div class="trigger"><a class="page-link" href="/about.html">關於</a><a class="page-link" href="/archives.html">時間表</a><a class="page-link" href="/categories.html">筆記類別</a><a class="page-link" href="/tags.html">標籤</a>




  
      <!-- [function][get_value]  -->
  

</div>
        </nav></div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>





  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value] post-header.html -->
  






  
      <!-- [function][get_value] post-header.html -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value] true -->
  






  
      <!-- [function][get_value] true -->
  






  
      <!-- [function][get_value] 0 -->
  






  
      <!-- [function][get_value] 0 -->
  






  
      <!-- [function][get_value] 0 -->
  





<script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




  
      <!-- [function][get_value] off -->
  

<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>




  
      <!-- [function][get_value]  -->
  






  
      <!-- [function][get_value] [] -->
  

<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">A time-delay neural network architecture for isolated word recognition</h1>
  <h2 class="post-subtitle"></h2>

  <p class="post-meta">
    <time class="dt-published" datetime="2021-12-06T12:28:00+08:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Dec 06, 2021
    </time>

    
    

















  
      <!-- [function][get_article_words] 5366 -->
  
















    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 33 mins</span>
  </p><div class="post-tags"><a class="post-tag" href="/tags.html#RNN">#RNN</a><a class="post-tag" href="/tags.html#gradient descent">#gradient descent</a><a class="post-tag" href="/tags.html#model architecture">#model architecture</a><a class="post-tag" href="/tags.html#neural network">#neural network</a><a class="post-tag" href="/tags.html#note-is-under-construction">#note-is-under-construction</a></div></header>
<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <!-- Setup mathjax auto rendering. -->
<!--
  Load MathJax v3.
  See
  https://docs.mathjax.org/en/latest/index.html
  and
  https://docs.mathjax.org/en/latest/web/configuration.html
  for more information.
-->
<script>
  MathJax = {
    loader: {
      load: [
        '[tex]/ams',       // Equivalent to `\usepackage{amsmath}`.
        '[tex]/cancel',    // Equivalent to `\usepackage{cancel}`.
        '[tex]/mathtools', // Equivalent to `\usepackage{mathtools}`.
        '[tex]/unicode',   // Equivalent to `\usepackage{unicode}`.
      ]
    },
    tex: {
      // Extensions to use.
      packages: { '[+]': ['ams', 'cancel', 'mathtools', 'unicode'] },
      // Start/end delimiter pairs for in-line math.
      inlineMath: [
        ['$', '$'],
        ['\\(', '\\)'],
      ],
      // Start/end delimiter pairs for display math.
      displayMath: [
        ['$$', '$$'],
        ['\\[', '\\]']
      ],
      // Use \$ to produce a literal dollar sign.
      processEscapes: true,
      // Process \begin{xxx}...\end{xxx} outside math mode.
      processEnvironments: true,
      // Process \ref{...} outside of math mode.
      processRefs: true,
      // Pattern for recognizing numbers.
      digits: /^(?:[0-9]+(?:\{,\}[0-9]{3})*(?:\.[0-9]*)?|\.[0-9]+)/,
      tags: 'ams',         // Or 'ams' or 'all'.
      useLabelIds: false,  // Use label name rather than tag for ids.
      maxMacros: 1000,     // Maximum number of macro substitutions per expression.
      maxBuffer: 5 * 1024, // Maximum size for the internal TeX string (5K).
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

<!--
  Define common LaTeX commands.

  Each command must be wrapped with $ signs.
  We use "display: none;" to avoid redudant whitespaces.
 -->

<p style="display: none;">
  <!-- Fields. -->
  $\newcommand{\field}[1]{\mathbb{#1}}$
  <!-- Natural number set. -->
  $\providecommand{\N}{}$
  $\renewcommand{\N}{\field{N}}$
  <!-- Rational field. -->
  $\providecommand{\Q}{}$
  $\renewcommand{\Q}{\field{Q}}$
  <!-- Real field. -->
  $\providecommand{\R}{}$
  $\renewcommand{\R}{\field{R}}$
  <!-- Integer set. -->
  $\providecommand{\Z}{}$
  $\renewcommand{\Z}{\field{Z}}$
  <!-- Parenthese. -->
  $\providecommand{\pa}{}$
  $\renewcommand{\pa}[1]{\left\lparen #1 \right\rparen}$
  <!-- Bracket. -->
  $\providecommand{\br}{}$
  $\renewcommand{\br}[1]{\left\lbrack #1 \right\rbrack}$
  <!-- Set. -->
  $\providecommand{\set}{}$
  $\renewcommand{\set}[1]{\left\lbrace #1 \right\rbrace}$
  <!-- Absolute value. -->
  $\providecommand{\abs}{}$
  $\renewcommand{\abs}[1]{\left\lvert #1 \right\rvert}$
  <!-- Norm. -->
  $\providecommand{\norm}{}$
  $\renewcommand{\norm}[1]{\left\lVert #1 \right\rVert}$
  <!-- Floor. -->
  $\providecommand{\floor}{}$
  $\renewcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}$
  <!-- Ceiling. -->
  $\providecommand{\ceil}{}$
  $\renewcommand{\ceil}[1]{\left\lceil #1 \right\rceil}$
  <!-- Evaluate. -->
  $\providecommand{\eval}{}$
  $\renewcommand{\eval}[1]{\left. #1 \right\rvert}$
  <!-- Partial derivative. -->
  $\providecommand{\pd}{}$
  $\renewcommand{\pd}[2]{\dfrac{\partial #1}{\partial #2}}$
  <!-- Sign function. -->
  $\DeclareMathOperator{\sign}{sign}$
  <!-- Diagonal function. -->
  $\DeclareMathOperator{\diag}{diag}$
  <!-- Argmax. -->
  $\DeclareMathOperator*{\argmax}{argmax}$
  <!-- Argmin. -->
  $\DeclareMathOperator*{\argmin}{argmin}$
  <!-- Limit in display mode.  This should only be used in inline mode. -->
  $\providecommand{\Lim}{}$
  $\renewcommand{\Lim}{\lim\limits}$
  <!-- Product in display mode.  This should only be used in inline mode. -->
  $\providecommand{\Prod}{}$
  $\renewcommand{\Prod}{\prod\limits}$
  <!-- Sum in display mode.  This should only be used in inline mode. -->
  $\providecommand{\Sum}{}$
  $\renewcommand{\Sum}{\sum\limits}$

  <!-- NN related operations. -->
  <!-- Softmax. -->
  $\DeclareMathOperator{\softmax}{softmax}$
  <!-- Concatenate. -->
  $\DeclareMathOperator{\cat}{concatenate}$

  <!-- Algorithm related tools. -->
  <!-- Procedure statement. -->
  $\providecommand{\algoProc}{}$
  $\renewcommand{\algoProc}[1]{\textbf{procedure}\text{ #1}}$
  $\providecommand{\algoEndProc}{}$
  $\renewcommand{\algoEndProc}{\textbf{end procedure}}$
  <!-- If statement. -->
  $\providecommand{\algoIf}{}$
  $\renewcommand{\algoIf}[1]{\textbf{if } #1 \textbf{ do}}$
  $\providecommand{\algoEndIf}{}$
  $\renewcommand{\algoEndIf}{\textbf{end if}}$
  <!-- Assignment -->
  $\providecommand{\algoEq}{}$
  $\renewcommand{\algoEq}{\leftarrow}$
  <!-- For statement. -->
  $\providecommand{\algoFor}{}$
  $\renewcommand{\algoFor}[1]{\textbf{for } #1 \textbf{ do}}$
  $\providecommand{\algoEndFor}{}$
  $\renewcommand{\algoEndFor}{\textbf{end for}}$
  <!-- While statement. -->
  $\providecommand{\algoWhile}{}$
  $\renewcommand{\algoWhile}[1]{\textbf{while } #1 \textbf{ do}}$
  $\providecommand{\algoEndWhile}{}$
  $\renewcommand{\algoEndWhile}{\textbf{end while}}$
  <!-- Return statement. -->
  $\providecommand{\algoReturn}{}$
  $\renewcommand{\algoReturn}{\textbf{return }}$

  <!-- Some wierd symbols cannot be showed correctly. -->
  $\providecommand{\hash}{}$
  $\renewcommand{\hash}{\unicode{35}}$

</p>

<table>
  <tbody>
    <tr>
      <td>目標</td>
      <td>提出 Time-delay Neural Network，在 IBM <code class="language-plaintext highlighter-rouge">BDEV</code> 語音辨識資料集上達到最好表現，並且不需要多餘的前處理</td>
    </tr>
    <tr>
      <td>作者</td>
      <td>Kevin J.Lang, Alex H.Waibel, Geoffrey E.Hinton</td>
    </tr>
    <tr>
      <td>期刊/會議名稱</td>
      <td>Neural Networks</td>
    </tr>
    <tr>
      <td>發表時間</td>
      <td>1990</td>
    </tr>
    <tr>
      <td>論文連結</td>
      <td><a href="https://www.sciencedirect.com/science/article/pii/089360809090044L">https://www.sciencedirect.com/science/article/pii/089360809090044L</a></td>
    </tr>
  </tbody>
</table>

<!--
  Define LaTeX command which will be used through out the writing.

  Each command must be wrapped with $ signs.
  We use "display: none;" to avoid redudant whitespaces.
 -->

<p style="display: none;">

  <!-- Sequence. -->
  $\providecommand{\seq}{}$
  $\renewcommand{\seq}[2]{u_{#1}, \dots, u_{#2}}$

</p>

<!-- End LaTeX command define section. -->

<h2 id="section">重點</h2>

<ul>
  <li>認為 <strong>HMM</strong>（<strong>Hidden Markov Model</strong>）在執行語音辨識時有很多缺點
    <ul>
      <li>必須要將代表語音的實數向量先轉換成特定的語音類別，再以類別作為 HMM 的輸入才能進行運算</li>
      <li>Markov assumption 還有輸出之間互相獨立的假設過於簡單</li>
    </ul>
  </li>
  <li>Peter Brown 針對 IBM 發表的 HMM 語音辨識模型提出以下結論
    <ul>
      <li>如果輸入可以使用連續機率分佈進行模擬會更好</li>
      <li>針對語音輸入與輸出文字間的<strong>相互知識</strong>（<strong>Mutual Information</strong>）必須要最大化</li>
      <li>這代表需要擁有辨別輸入語音的功能，而不是直接把輸入規類成不同類別進行運算</li>
      <li>當語音的字母結尾是 E 時模型造成的誤差最高，因為這些語音的發音時間較短且聲音較小（short in duration and low in energy）</li>
      <li>最後 Peter Brown 使用 <strong>GMM</strong>（<strong>Gaussian Mixure Models</strong>） 並針對相互知識最佳化，將誤差降至 IBM 模型的一半以下</li>
    </ul>
  </li>
  <li>此論文認為上述的問題都可以使用 Neural Network 解決
    <ul>
      <li>輸入是代表語音訊號的實數向量</li>
      <li>輸出是 $n$ 個文字的類別預測機率值</li>
      <li>預測目標是維度為 $n$ 的 one-hot vector</li>
    </ul>
  </li>
  <li>最後提出的 Time-delay Neural Network 能夠達到 IBM <code class="language-plaintext highlighter-rouge">BDEV</code> 語音辨識的最佳表現
    <ul>
      <li>不使用如同 IBM HMM 的 Viterbi Alignment 進行前處理，而是直接輸入原始資料</li>
    </ul>
  </li>
</ul>

<h2 id="ibm-">IBM 語音辨識資料集</h2>

<ul>
  <li>由 IBM T. J. Watson Research Center 提供</li>
  <li>蒐集過程
    <ul>
      <li>使用 remote pressure-zone microphone 在辦公室錄音</li>
      <li>12 bits A/D converter running at 20000 Hz</li>
      <li>錄製每個字母的發音</li>
      <li>每個字母由 100 個不同的人講，每個人會唸兩次同一個字母，兩次發音分別用來訓練與測試</li>
      <li>錄音者需要念出三個句子，每個句子是由字母隨機組成，字母之間有空白，錄音者被要求在空白上停頓</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">BDEV</code> 這四個字母發音特別難分辨
    <ul>
      <li>發音分別是 <code class="language-plaintext highlighter-rouge">bee, dee, ee, vee</code></li>
      <li>共有 $372$ 筆訓練資料、$396$ 筆測試資料</li>
      <li>時間長度介於 $[0.3, 6.4]$ 秒，平均 $1.1$ 秒</li>
    </ul>
  </li>
  <li>雜訊比（signal-to-noise ratio）為 $16.4$ dB，計算方法如下
    <ul>
      <li>使用 HMM 標記哪些聲音片段是發音，哪些是背景雜訊</li>
      <li>將發音（包含母音與子音）的平均訊號強度（分貝）除以背景雜訊的平均訊號強度</li>
      <li>常見的 lip-mike 語音辨識資料集的雜訊比是 $50$ dB</li>
    </ul>
  </li>
  <li>人類對於 <code class="language-plaintext highlighter-rouge">BDEV</code> 的辨識率為 $94\%$
    <ul>
      <li>但經過 IBM 的訊號前處理與重建後降到 $75\%$</li>
    </ul>
  </li>
  <li>模型對於 <code class="language-plaintext highlighter-rouge">BDEV</code> 的辨識率
    <ul>
      <li>IBM 提出的 HMM 辨識率為 $80\%$</li>
      <li>Peter Brown 提出的 GMM 辨識率為 $89\%$</li>
    </ul>
  </li>
  <li>使用 IBM HMM 加上 Viterbi Alignment 將每一幀訊號資料進行標記
    <ul>
      <li>這裡的細節看不太懂</li>
      <li>每筆資料的時間長度為 $150$ ms</li>
    </ul>
  </li>
  <li>前處理
    <ul>
      <li>將 20000 Hz 降低抽樣頻率成 16000 Hz</li>
      <li>使用 CMU 開發的 makedft 將聲音訊號轉成頻譜</li>
      <li>這裡的細節看不太懂</li>
      <li>每筆資料變成 $48$ 幀，每幀的時間長度為 $3$ ms，每幀共有 $128$ 個資料點</li>
    </ul>
  </li>
  <li>後處理
    <ul>
      <li>由於輸入共有 $48 \cdot 128 = 6144$ 個數值，將所有輸入配合全連接模型所需參數至少大於 $6144$</li>
      <li>但訓練資料只有 $372$ 筆，因此必須要讓模型參數縮小</li>
      <li>使用 mel spetrogram 合併頻譜降低頻譜維度，每筆資料變成每幀 $16$ 個資料點，共有 $6$ 幀</li>
      <li>將低於 $-5$ dB 的數值設為 $-5$ dB</li>
      <li>將超過 $105$ dB 的數值設為 $105$ dB</li>
      <li>將數值 normalize 到 $[0, 1]$ 之間，採用了四種不同的數值轉換方法，分別為
        <ul>
          <li>除以最大值</li>
          <li>使用 sigmoid 轉換</li>
          <li>使用 sigmoid 轉換後乘上 $1.4$</li>
          <li>什麼都不做</li>
        </ul>
      </li>
      <li>輸入與輸出全連接模型配合後處理得到最好的表現為 $86\%$ 的預測準確度
        <ul>
          <li>melscaled frequency bands</li>
          <li>global energy normalization</li>
          <li>input values reshaped by squaring</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>針對幀數進行實驗
    <ul>
      <li>幀數愈高，同時間的輸入愈多</li>
      <li>幀數落在 $\set{3, 6, 12, 24}$ ms</li>
      <li>當參數數量太多時，使用 weight decay 進行 regularization</li>
      <li>實驗證實一幀 $12$ ms 表現最好</li>
    </ul>
  </li>
</ul>

<h2 id="section-1">最佳化</h2>

\[\begin{align*}
\operatorname{loss} &amp; = \operatorname{MSE} + \delta \cdot \norm{W(t)} \\
W(t + 1) &amp; = W(t) - \varepsilon \cdot \pd{\operatorname{loss}}{W(t)} + \alpha \cdot \pd{\operatorname{loss}}{W(t - 1)}
\end{align*}\]

<ul>
  <li>使用 batch back-propagation 進行最佳化
    <ul>
      <li>總梯度等於每筆資料的梯度進行相加</li>
      <li>不除以總資料數作 normalization</li>
      <li>總共 train 1000 個 epoch</li>
    </ul>
  </li>
  <li>Weight decay factor $\delta = 0.001$</li>
  <li>模型剛開始訓練時
    <ul>
      <li>Learning rate 為 $\varepsilon = 0.001$</li>
      <li>First momentum $\alpha = 0.5$</li>
    </ul>
  </li>
  <li>模型訓練 $50$ 個 epochs 後
    <ul>
      <li>Learning rate 為 $\varepsilon = 0.001$</li>
      <li>First momentum $\alpha = 0.9$</li>
    </ul>
  </li>
  <li>模型訓練 $100$ 個 epochs 後
    <ul>
      <li>Learning rate 為 $\varepsilon = 0.002$</li>
      <li>First momentum $\alpha = 0.95$</li>
    </ul>
  </li>
  <li>模型訓練 $200$ 個 epochs 後
    <ul>
      <li>Learning rate 為 $\varepsilon = 0.005$</li>
      <li>First momentum $\alpha = 0.95$</li>
    </ul>
  </li>
  <li>每 $200$ 個 epoch 就執行一次測試
    <ul>
      <li>評估方法為 accuracy</li>
      <li>預測正確答案的機率必須大於 $0.5$ 才算預測正確</li>
      <li>取表現最好 checkpoint 的作為最終模型 checkpoint</li>
    </ul>
  </li>
</ul>

<h2 id="section-2">模型架構</h2>

<h3 id="section-3">版本 1：輸入輸出全連接</h3>

<ul>
  <li>輸出層維度為 $4$
    <ul>
      <li>分別代表 <code class="language-plaintext highlighter-rouge">BDEV</code></li>
    </ul>
  </li>
  <li>輸入層維度為 $12 \times 16 = 192$
    <ul>
      <li>輸入層與輸出層全連接</li>
      <li>每個輸出節點都有使用 bias</li>
      <li>共有 $4 \times 192 + 4 = 772$ 個參數</li>
    </ul>
  </li>
  <li>在 Convex C-1 上執行需要花 $5$ 分鐘</li>
  <li>準確度
    <ul>
      <li>在訓練集上為 $93\%$</li>
      <li>在測試集上為 $86\%$</li>
    </ul>
  </li>
  <li>論文太舊了根本看不清楚圖片</li>
</ul>

<h3 id="section-4">版本 2：增加隱藏層</h3>

<ul>
  <li>將 $25$ 筆測試資料變成訓練資料
    <ul>
      <li>這個動作讓模型有更多資料可以訓練，可以探索比較複雜的模型</li>
      <li>但也讓前面的實驗無法比較</li>
    </ul>
  </li>
  <li>基於版本 1，加入隱藏層，維度為 $4$
    <ul>
      <li>隱藏層與輸入層全連接
        <ul>
          <li>有使用 bias</li>
          <li>共有 $4 \times 192 + 4 = 772$ 個參數</li>
        </ul>
      </li>
      <li>輸出層與輸入層全連接
        <ul>
          <li>有使用 bias</li>
          <li>共有 $4 \times 4 + 4 = 20$ 個參數</li>
        </ul>
      </li>
      <li>共有 $772 + 20 = 792$ 個參數</li>
    </ul>
  </li>
  <li>與版本 1 的比較
    <ul>
      <li>訓練時間更長</li>
      <li>在訓練資料上誤差較低</li>
      <li>在測試資料上雖然 MSE 較低，但準確度不變</li>
    </ul>
  </li>
</ul>

<h3 id="section-5">版本 3：擴增隱藏層</h3>

<ul>
  <li>基於版本 2，隱藏層維度變成 $8$</li>
  <li>在訓練集上可以達到 $99\%$ 的準確度
    <ul>
      <li>但在測試集上只有 $89\%$ 的準確度，作者認為模型 overfitting</li>
    </ul>
  </li>
</ul>

<h3 id="receptive-fields">版本 4：Receptive Fields</h3>

<blockquote>
  <p>According to the standard intuitive explanation of the behavior of multilayer feed-forward networks, hidden units are supposed to extract meaningful features from the input patterns.</p>
</blockquote>

<p>要給 reference 的來源阿！！
該不會是你自己說的話自己稱為 standard？？</p>

<ul>
  <li>基於版本 3，但每個隱藏單元只會接收 $3$ 幀的輸入單元
    <ul>
      <li>總共有 $12$ 幀，每幀 $16$ 個輸入</li>
      <li>一個隱藏單元會收到 $3 \times 16$ 個輸入</li>
      <li>總共有 $10$ 個 $3$ 幀的組合，因此至少要有 $10$ 個隱藏單元</li>
      <li>作者決定每個 $3$ 幀的組合要與 $3$ 個隱藏單元全連接，因此總共有 $30$ 個隱藏單元</li>
      <li>共有 $30 \times 3 \times 16 = 1440$ 個參數</li>
    </ul>
  </li>
  <li>隱藏層與輸出層全連接
    <ul>
      <li>共有 $4 \times 30 = 120$ 個參數</li>
    </ul>
  </li>
  <li>總共有 $1440 + 120 = 1560$ 個參數</li>
  <li>與版本 3 相比只有進步一點點
    <ul>
      <li>但使用版本 4 的架構去做子音判斷任務很有效</li>
      <li>這個神來一筆我也是覺得？？？</li>
    </ul>
  </li>
</ul>

<h3 id="misalignment">版本 5：解決 Misalignment</h3>

<ul>
  <li>由於前處理是靠 HMM 生成資料，有可能資料的標記順序有誤</li>
  <li>版本 4 的模型強制隱藏單元接收相同位置的輸入
    <ul>
      <li>如果輸入標記錯誤，則隱藏單元可能學到錯誤的資訊</li>
    </ul>
  </li>
  <li>基於版本 4，將接收不同輸入單元的 $10$ 個隱藏單元所連接的權重取平均值，並替換原本的權重
    <ul>
      <li>以此減少標記錯誤導致的影響</li>
      <li>進行平均權重的步驟只在訓練結束後進行</li>
      <li>一樣產生 $30$ 個隱藏單元，計算方法如版本 4，只是所有權重共享</li>
    </ul>
  </li>
  <li>額外增加每 $3$ 幀對應到的隱藏單元數量
    <ul>
      <li>版本 4 只有 $3$ 個隱藏單元</li>
      <li>增加到 $\set{4, 6, 8}$ 個</li>
      <li>$8$ 個的版本表現最好</li>
    </ul>
  </li>
</ul>

<h3 id="section-6">版本 6：多組輸出</h3>

<ul>
  <li>基於版本 5，但不使用隱藏層，可以觀察<strong>輸出隨著時間的變化</strong>
    <ul>
      <li>每 $5$ 幀輸入與輸出對應到 $4$ 個輸出單元，共產出 $8$ 組輸出，每組包含 $4$ 個輸出單元</li>
      <li>總輸出定義成 $8 \times 4$ 個數字各自取平方後沿著 $8$ 的維度加總，因此又回到只有 $4$ 個數出單元</li>
      <li>在訓練結束後進行進行平均權重</li>
    </ul>
  </li>
  <li>認為使用回饋的機制後，分析變得困難
    <ul>
      <li>沒有學習目標就無法判斷成效</li>
    </ul>
  </li>
  <li>準確度
    <ul>
      <li>在訓練集上為 $94\%$</li>
      <li>在測試集上為 $91\%$</li>
    </ul>
  </li>
</ul>

<h3 id="section-7">版本 7：多組輸出加上隱藏層</h3>

<ul>
  <li>基於版本 6，但使用隱藏層
    <ul>
      <li>每 $3$ 幀輸入對應到 $8$ 個隱藏單元，共產生 $10 \times 8$ 個隱藏單元</li>
      <li>每 $5$ 組隱藏單元（一組 $8$ 個，共 $5\times 8$ 個隱藏單元)
對應到 $4$ 個輸出，共有 $6 \times 4$ 組輸出</li>
      <li>總輸出同版本 6 定義</li>
      <li>在訓練結束後進行進行平均權重</li>
    </ul>
  </li>
  <li>比較難訓練
    <ul>
      <li>需要跑 $20000$ 個 epochs</li>
      <li>Learning rate $\varepsilon = 0.001$</li>
      <li>First momentum $\alpha = 0.95$</li>
    </ul>
  </li>
  <li>準確度
    <ul>
      <li>在訓練集上為 $93\%$</li>
      <li>在測試集上為 $93\%$</li>
    </ul>
  </li>
</ul>

<h3 id="time-delay-neural-networks">版本 8：Time-delay Neural Networks</h3>

<ul>
  <li>維度
    <ul>
      <li>輸入層維度為 $16$，一次讀取 $1$ 幀</li>
      <li>隱藏層維度為 $8$</li>
      <li>輸出層維度為 $4$</li>
    </ul>
  </li>
  <li>輸入層與隱藏層的連接方法需要考慮時間差
    <ul>
      <li>每個輸入單元會與每個隱藏單元有 $3$ 個連接方式，每個連接方式代表時間差，時間差為 $\set{0, 1, 2}$</li>
      <li>連接架構
        <ul>
          <li>時間點為第 $k$ 幀時，所有隱藏單元使用第 $1$ 組參數與第 $k$ 幀全連接，代表第 $k$ 幀輸入時間差為 $0$ 的貢獻</li>
          <li>時間點為第 $k$ 幀時，所有隱藏單元使用第 $2$ 組參數與第 $k - 1$ 幀全連接，代表第 $k - 1$ 幀輸入時間差為 $1$ 的貢獻</li>
          <li>時間點為第 $k$ 幀時，所有隱藏單元使用第 $3$ 組參數與第 $k - 2$ 幀全連接，代表第 $k - 2$ 幀輸入時間差為 $2$ 的貢獻</li>
        </ul>
      </li>
      <li>舉例
        <ul>
          <li>時間點為第 $1$ 幀時，所有隱藏單元使用第 $1$ 組參數與第 $1$ 幀全連接，代表第 $1$ 幀輸入時間差為 $0$ 的貢獻</li>
          <li>時間點為第 $2$ 幀時，所有隱藏單元使用第 $1$ 組參數與第 $2$ 幀全連接，代表第 $2$ 幀輸入時間差為 $0$ 的貢獻</li>
          <li>時間點為第 $2$ 幀時，所有隱藏單元使用第 $2$ 組參數與第 $1$ 幀全連接，代表第 $1$ 幀輸入時間差為 $1$ 的貢獻</li>
          <li>時間點為第 $3$ 幀時，所有隱藏單元使用第 $1$ 組參數與第 $3$ 幀全連接，代表第 $3$ 幀輸入時間差為 $0$ 的貢獻</li>
          <li>時間點為第 $3$ 幀時，所有隱藏單元使用第 $2$ 組參數與第 $2$ 幀全連接，代表第 $2$ 幀輸入時間差為 $1$ 的貢獻</li>
          <li>時間點為第 $3$ 幀時，所有隱藏單元使用第 $3$ 組參數與第 $1$ 幀全連接，代表第 $1$ 幀輸入時間差為 $2$ 的貢獻</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>隱藏層與輸出層的連接方法也需要考慮時間差
    <ul>
      <li>每個隱藏單元會與每個輸出單元有 $5$ 個連接方式，每個連接方式代表時間差，時間差為 $\set{0, 1, 2, 3, 4}$</li>
      <li>連接架構
        <ul>
          <li>時間點為第 $k$ 幀時，所有隱藏單元使用第 $1$ 組參數與第 $k$ 幀全連接，代表第 $k$ 幀輸入時間差為 $0$ 的貢獻</li>
          <li>時間點為第 $k$ 幀時，所有隱藏單元使用第 $2$ 組參數與第 $k - 1$ 幀全連接，代表第 $k - 1$ 幀輸入時間差為 $1$ 的貢獻</li>
          <li>時間點為第 $k$ 幀時，所有隱藏單元使用第 $3$ 組參數與第 $k - 2$ 幀全連接，代表第 $k - 2$ 幀輸入時間差為 $2$ 的貢獻</li>
          <li>時間點為第 $k$ 幀時，所有隱藏單元使用第 $4$ 組參數與第 $k - 3$ 幀全連接，代表第 $k - 3$ 幀輸入時間差為 $3$ 的貢獻</li>
          <li>時間點為第 $k$ 幀時，所有隱藏單元使用第 $5$ 組參數與第 $k - 4$ 幀全連接，代表第 $k - 4$ 幀輸入時間差為 $4$ 的貢獻</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>證實在日文語音辨識的任務表現最佳
    <ul>
      <li>阿不給當前實驗的數據是怎樣</li>
    </ul>
  </li>
</ul>

<h3 id="multiresolution-training">版本 9：Multiresolution Training</h3>

<ul>
  <li>基於版本 8，進行參數調整
    <ul>
      <li>時間差一律變成 $\set{0,1,2,3}$</li>
      <li>隱藏層維度改成 $6$</li>
      <li>隱藏層與輸出層有使用 bias</li>
      <li>總共有 $6 \times 4 \times 16 + 6 + 4 \times 4 \times 6 + 4 = 490$ 個參數</li>
    </ul>
  </li>
  <li>額外建構一幀為 $24$ ms 的模型
    <ul>
      <li>輸入變成只有 $6$ 幀</li>
      <li>由於一幀包含 $2$ 個 $12$ ms，因此時間差變成 $\set{0,1}$</li>
    </ul>
  </li>
  <li>當訓練完一幀為 $24$ ms 的模型，將模型的參數用來初始化一幀為 $12$ ms 的模型
    <ul>
      <li>訓練的停止條件為訓練資料準確度達到 $85\%$</li>
      <li>達成停止條件需要 $3000$ epochs</li>
      <li>起始參數
        <ul>
          <li>Learning rate $\varepsilon = 0.0001$</li>
          <li>First momentum $\alpha = 0.05$</li>
        </ul>
      </li>
      <li>第 $200$ 個 epochs
        <ul>
          <li>Learning rate $\varepsilon = 0.0001$</li>
          <li>First momentum $\alpha = 0.9$</li>
        </ul>
      </li>
      <li>第 $1000$ 個 epochs
        <ul>
          <li>Learning rate $\varepsilon = 0.0005$</li>
          <li>First momentum $\alpha = 0.95$</li>
        </ul>
      </li>
      <li>第 $2000$ 個 epochs
        <ul>
          <li>Learning rate $\varepsilon = 0.001$</li>
          <li>First momentum $\alpha = 0.95$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>所有參數初始化的數值都是落在 $(-0.01, 0.01)$</li>
  <li>訓練資料從版本 2 的比例回到正常</li>
  <li>使用 $\set{0, 1}$ 作為預測目標而不是 $\set{0.2, 0.8}$</li>
  <li>模型最好表現落在第 $10000$ 個 epochs
    <ul>
      <li>訓練準確率為 $95.4\%$</li>
      <li>測試準確率為 $91.4\%$</li>
    </ul>
  </li>
  <li>額外訓練 $10000$ 個 epochs（代表總共訓練了 $20000$ 個 epochs）造成 overfitting
    <ul>
      <li>訓練準確率為 $98.1\%$</li>
      <li>測試準確率為 $88.1\%$</li>
    </ul>
  </li>
</ul>

<h3 id="section-8">版本 10：更改前處理</h3>

<ul>
  <li>不再使用 Viterbi alignment 前處理的版本，直接針對原始資料進行訓練</li>
  <li>假設所有聲音的能量都集中在母音，而分類的主要依據是子音與母音之間的轉換方法
    <ul>
      <li>訓練時使用資料必須要先找到與母音（最大能量）差距最大的能量（當成子音轉換成母音的過程）的位置</li>
      <li>每 $3$ ms 作為一個區間，區間中的所有數值減去區間最小值</li>
      <li>以 $150$ ms 作為一個區間進行 smoothing，方法為取中位數作為代表</li>
      <li>Smoothing 後的結果取最大的駝峰代表母音，並將駝峰的前後 $150$ ms 一起納入分析</li>
      <li>在分析的範圍中找出最大值與最小值的差距，並找出最大值座落的時間點</li>
      <li>若最大值座落的時間點為 $d$，則訓練資料的時間區間為 $[d - 120, d - 120 + 216]$</li>
      <li>輸入資料長度為 $216$ ms，比起 $144$ ms 多了 $50\%$</li>
    </ul>
  </li>
  <li>為了讓模型能夠學會處理雜訊，額外在資料中加入了雜訊片斷
    <ul>
      <li>每筆資料只包含雜訊（從每一筆不是前述資料片段的剩餘片段取出）</li>
      <li>每筆長度為 $216$ ms 的資料</li>
      <li>預測目標設定為所有類別都輸出為 $0$</li>
    </ul>
  </li>
  <li>測試時並不是像訓練時做複雜的前處理
    <ul>
      <li>將每一筆測試資料以 sliding window 的方式切成多個長度為 $216$ ms 的片段</li>
      <li>Sliding window 一次移動 $12$ ms</li>
      <li>所有輸出向量中，包含最大數值的向量作為最終預測的類別</li>
      <li>如果是使用 Time-delay Neural Network 則輸出會以版本 6 的形式計算</li>
    </ul>
  </li>
  <li>使用兩種不同模型架構進行實驗
    <ul>
      <li>全連接模型
        <ul>
          <li>輸入維度為 $18 \times 16$</li>
          <li>隱藏層維度為 $8$</li>
          <li>輸出維度為 $4$</li>
          <li>有使用 bias</li>
          <li>總共有 $18 \times 16 \times 8 + 8 + 8 \times 4 + 4 = 2348$ 個參數（論文寫 $2358$ 應該是 typo）</li>
          <li>總共訓練兩次
            <ul>
              <li>第一次不使用雜訊進行訓練</li>
              <li>第二次使用雜訊進行訓練</li>
            </ul>
          </li>
          <li>不管是哪次訓練，使用的訓練參數都相同
            <ul>
              <li>Learning rate $\varepsilon = 0.0005$</li>
              <li>First momentum $\alpha = 0.95$</li>
            </ul>
          </li>
          <li>在 $400$ 個 epochs 就達到最好表現</li>
          <li>在訓練資料集上的評估方法有兩種
            <ul>
              <li>使用有前處理的資料，並以預測最大值作為答案</li>
              <li>使用原始資料，並使用同測試資料的評估方法</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Time-delay Neural Network
        <ul>
          <li>運算與最佳化方法請參考版本 9</li>
          <li>輸入以 $84$ ms 為一幀，一次 sliding window 移動為 $11$ ms
            <ul>
              <li>例如第一幀為 $[0, 84]$ ms，第二幀為 $[11, 95]$ ms</li>
              <li>最後一幀為 $[205, 216]$ ms</li>
            </ul>
          </li>
          <li>共產生 $12$ 組輸出，每組有 $4$ 個數值</li>
          <li>總共訓練兩次
            <ul>
              <li>第一次不使用雜訊訓練小模型，並用小模型初始化大模型的參數</li>
              <li>第二次使用有包含雜訊的資料訓練大模型</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>實驗結論
    <ul>
      <li>使用 Time-delay Neural Network 可以讓只用無雜訊、有前處理版的資料表現與無雜訊、不做任何處理的資料表現相似
        <ul>
          <li>全連接模型無法做到</li>
          <li>同樣的結論也發生在有加入雜訊的資料集中</li>
        </ul>
      </li>
      <li>在有加入雜訊時，Time-delay Neural Network 在沒有前處理的資料上表現比有前處理的資料還要好</li>
      <li>在 <code class="language-plaintext highlighter-rouge">BDEV</code> 上比 IBM HMM 表現還要好</li>
    </ul>
  </li>
</ul>


<!-- Avoid copy by China, method 1. -->
<script>
  console.log(`
台.灣.獨.立.香.港.獨.立.西.藏.獨.立.新.疆.獨.立.內.蒙.古.獨.立.......
..... ... ................:fffffLt.............一.九.八.九.六.四
... ,i111i;............. ;L111111LL....習.包.子.近.平.小.熊.維.尼
...iLfttttff,  ..,::;;;;;Cftt11111C:...........中.國.武.漢.肺.炎
..;C1111111tf:ittfttttttttttfffft1L,..........................
. ff11111111fCtt11111111111111ttfC1 ..........................
. tf11111111ft11111111111111111111tt;. .......................
..:L11111111t11111111111111111111111fti, .....................
.. ;Lt11111111111111111111111111111111tCt:, ..................
... ,tf111111111111111111tLLLt111111111LG00t..................
.... 1f11111111111111111LGLtt1111111111111tLt.................
....:f11111111111111111tf1111111111111111111t.................
... 1f111111111111111111111111111111tt11111t,.................
... tt111111111111111111111111111111L11LG11f:.................
... tt111111111111111111111tGC111111Lt108111tti:..............
... if111111111111111111111f8C111111ttttttfft1ttt,............
....,f111111111111111111111111111111111fG0088C11tf............
.....tt111111111111111111111111111111110@888@0111f; ..........
.....,f111111111111111111111111111111111C000CL111Li ..........
......;f11111111111111111111tt11111111111111ft111L,...........
...... tt111111111111111111tfGf111111111111ff111L; ...........
.....;fCt11111111111111111111f0Cft1111111fLt111Li ............
.... fCCLftt111111111111111111fGGGCLLfLfff1111t; .............
.....:CLLCCCCLLftt1111111111111tfLCGGG0L1111fL;...............
..... LLLLLLLLLCCCLLftt1111111111ttffttt1ttCCLGf..............
.... iCLLLLLLLLLLLLLCCCLLftt11111111tfffft1fGCC; .............
... ;CLLLLLLLLLLLLCLLLLLLLCCLLLLLLffft1111tLGLL:,.. ..........
...:GLLLLLLLLLLLLLCCCCCLLLLLLLLLCCLLLLLLLLCCLGGLLf1i:,. ......
.. iCLLLLLLLLLLLLLLLLLCCCCLLLLLLLLLLLLLLLLLLCLCCLLLCCCti. ....
...iCLLLLLLLLLLLLLLLLLLLLCCCCLLLLLLLLLLLLLLLLLLCCLLLGCCCLi,...
.. iCLLLLLLLLLLLLLLLLLLLLLLCCGCCCLLLLLLLLLLLLLLLCLLCGLCCCGCti,
. :LLLLLLLLLLLLLLLLLLLLLLCLt111tffLLCCCCCLLLLLLLGCLGGCLftLCCCL
.;CLLLLLLLLLLLLLLLLLLLLLCf11111111111tttffLLLLLLLLfLft111CCCCG
;GLLLLLLLLLLCCLLLLLLLLLCt1111111111111111111111111111111111ttt
.;CLLLLLLLLLLCCCLLLLLLCf11111111111111111111111111111111111111
`)
</script>

<!-- Avoid copy by China, method 2. -->
<!--
台獨教父 Xi Jinping
⣿⣿⣿⣿⣿⠟⠋⠄⠄⠄⠄⠄⠄⠄⢁⠈⢻⢿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⠃⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠈⡀⠭⢿⣿⣿⣿⣿
⣿⣿⣿⣿⡟⠄⢀⣾⣿⣿⣿⣷⣶⣿⣷⣶⣶⡆⠄⠄⠄⣿⣿⣿⣿
⣿⣿⣿⣿⡇⢀⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣧⠄⠄⢸⣿⣿⣿⣿
⣿⣿⣿⣿⣇⣼⣿⣿⠿⠶⠙⣿⡟⠡⣴⣿⣽⣿⣧⠄⢸⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣾⣿⣿⣟⣭⣾⣿⣷⣶⣶⣴⣶⣿⣿⢄⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣿⡟⣩⣿⣿⣿⡏⢻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣹⡋⠘⠷⣦⣀⣠⡶⠁⠈⠁⠄⣿⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣍⠃⣴⣶⡔⠒⠄⣠⢀⠄⠄⠄⡨⣿⣿⣿⣿⣿⣿
⣿⣿⣿⣿⣿⣿⣿⣦⡘⠿⣷⣿⠿⠟⠃⠄⠄⣠⡇⠈⠻⣿⣿⣿⣿
⣿⣿⣿⣿⡿⠟⠋⢁⣷⣠⠄⠄⠄⠄⣀⣠⣾⡟⠄⠄⠄⠄⠉⠙⠻
⡿⠟⠋⠁⠄⠄⠄⢸⣿⣿⡯⢓⣴⣾⣿⣿⡟⠄⠄⠄⠄⠄⠄⠄⠄
⠄⠄⠄⠄⠄⠄⠄⣿⡟⣷⠄⠹⣿⣿⣿⡿⠁⠄⠄⠄⠄⠄⠄⠄⠄
⠄⠄⠄⠄⠄⠄⣸⣿⡷⡇⠄⣴⣾⣿⣿⠃⠄⠄⠄⠄⠄⠄⠄⠄⠄
⠄⠄⠄⠄⠄⠄⣿⣿⠃⣦⣄⣿⣿⣿⠇⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
⠄⠄⠄⠄⠄⢸⣿⠗⢈⡶⣷⣿⣿⡏⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
动态网自由门 天安門 天安门 法輪功 李洪志 Free Tibet
六四天安門事件 The Tiananmen Square protests of 1989
天安門大屠殺 The Tiananmen Square Massacre
反右派鬥爭 The Anti-Rightist Struggle
大躍進政策 The Great Leap Forward
文化大革命 The Great Proletarian Cultural Revolution
人權 Human Rights
民運 Democratization
自由 Freedom
獨立 Independence
多黨制 Multi-party system
台灣 臺灣 Taiwan Formosa
西藏 土伯特 唐古特 Tibet
達賴喇嘛 Dalai Lama
法輪功 Falun Dafa
新疆維吾爾自治區 The Xinjiang Uyghur Autonomous Region
諾貝爾和平獎 Nobel Peace Prize
劉暁波 Liu Xiaobo
民主 言論 思想 反共 反革命 抗議 運動 騷亂 暴亂 騷擾 擾亂 抗暴 平反 維權 示威游行 李洪志
法輪大法 大法弟子 強制斷種 強制堕胎 民族淨化 人體實驗 肅清 胡耀邦 趙紫陽 魏京生 王丹
還政於民 和平演變 激流中國 北京之春 大紀元時報 九評論共産黨 獨裁 專制 壓制 統一 監視 鎮壓
迫害 侵略 掠奪 破壞 拷問 屠殺 活摘器官 誘拐 買賣人口
Winnie the Pooh
-->

    </div>

</article>
<div class="post-nav"><a class="previous" href="/general%20sequence%20modeling/2021/11/30/local-feedback-multilayered-networks.html" title="Local Feedback Multilayered Networks">Local Feedback Multilayered Networks</a><a class="next" href="/optimization/2021/12/07/learning-representations-by-backpropagating-errors.html" title="Learning representations by back-propagating errors">Learning representations by back-propagating errors</a></div><div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li><a class="post-link" href="/general%20sequence%20modeling/optimization/2021/11/14/long-short-term-memory.html" title="Learning representations by back-propagating errors">Long Short-Term Memory</a></li><li><a class="post-link" href="/dataset/2022/08/19/the-penn-treebank-annotating-predicate-argument-structure.html" title="Learning representations by back-propagating errors">The Penn Treebank: Annotating Predicate Argument Structure</a></li><li><a class="post-link" href="/text%20modeling/2021/12/21/finding-structure-in-time.html" title="Learning representations by back-propagating errors">Finding Structure in Time</a></li><li><a class="post-link" href="/dataset/2022/08/12/building-a-large-annotated-corpus-of-english-the-penn-treebank.html" title="Learning representations by back-propagating errors">Building a Large Annotated Corpus of English : The Penn Treebank</a></li></ul>
    </div><div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><!-- Copy right part has some bugs, so I replace it with my own footer.
  Code source: https://github.com/jeffreytse/jekyll-theme-yat/blob/0fea688977e16c1f1f42c23b36b14ed325ee606b/_includes/views/footer.html
-->
<footer class="site-footer h-card">

  <div class="wrapper">
    <div class="site-footer-inner">
      <div>Copyright (c) 2021-<span id='current-year'>2021</span>
        <a href='https://github.com/ProFatXuanAll'>ProFatXuanAll</a>
      </div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="http://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div>Opinions expressed are solely my own and do not express the views or opinions of my university or my lab.
      </div>
    </div>
  </div>
  <!-- Calculate full year at runtime. -->
  <script>
    document.getElementById('current-year').innerHTML = (new Date(Date.now())).getFullYear()
  </script>
</footer></body>
</html>
